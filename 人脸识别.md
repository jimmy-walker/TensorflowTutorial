# 研究思路

##先定性（分类），找框架（cnn，tf），github上找代码（cnn face detection tensorflow）

我的话主要是通过老板给的任务积累的，看这个任务是什么问题，分类、检测还是分割，然后找到对应的框架。找到框架之后看有没有前人的代码，要是有就扒下来读一读看能不能读懂，然后把输入输出改成与自己问题相对应的，在这个过程里会遇到各种问题，把这些问题都解决了这个框架就差不多就算会了。当然我觉得如果能完全自己从头开始构建肯定提升的效果更好，可以先选择一些简单的问题来尝试一下。

那就是写一个**分类器**，我大三进入NLP实验室，听到新来的研究生师兄师姐们第一个任务总是写一个分类器。而我期间干了很多杂事以及上课，并没有真正的写过一个分类器。再加上考研的原因，我真正写一个自己基本都懂各种细节的文本分类器是在考完研的那个寒假。这个的功能就是给你一句话，你给这句话分个类即可。刚开始最好用CNN这个神经网络，因为这个简单。而你得需要数据，这个你可以去github上搜索，比如cnn text classification +自己喜欢用的框架（tensorflow，pytorch等），里面有代码，也基本会有数据。github真是个好东西，一定要充分利用。



## 相关业界新闻

某著名手机厂商想开发一个自己的人脸解锁功能，在第一次使用手机的时候，经过一个人脸注册的过程，记录下手机主人的样子，在之后的使用中如果被触发，就进行人脸验证，解锁。这里你如果上来一个几十层网络的卷积网络，这个是不行的……因为速度很重要，内存也重要，如果你一个网络模型一上来就已经几十兆几百兆了，产品经理会疯的。做产品的往往是想在保证用户体验的情况下，使用最少的资源。所以最后的产品可能是……下面是我瞎掰的……检测到人脸，检测五官的基本landmark，然后通过几何关系约束来缩小识别范围，再用简单的特征比如LBP，在一个一千张主人人脸的数据库进行验证，验证里可能有各种trick，并且这个一千张人脸的数据库也是实时更新的，比如当前识别正确了，那么就加入进去，如果识别错了，就把这个数据提取特征作为反例存起来……一个可用的产品总是包含了很多看似没有道理的trick的，但是就是这些构成了产品的核心技术。



LFW号称是最难的人脸图像库。



